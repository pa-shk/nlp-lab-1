{
 "nbformat": 4,
 "nbformat_minor": 0,
 "metadata": {
  "colab": {
   "provenance": [],
   "collapsed_sections": [
    "lPTEgLjVHr3q",
    "XUtIbPDda2RY",
    "L59BISnlpLuB",
    "OxD84dREpdFE",
    "VF_Tvcw6NDzg",
    "nk97qWsnFt8L",
    "Jk5KaSmBF6az",
    "G8zO2lhKG6HG",
    "MChopVCrJCx8"
   ]
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Intro"
   ],
   "metadata": {
    "id": "0gRWMwrwwrpr"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "In this lab, I've tried to create a language model for writing my diploma.\n",
    "\n",
    "Scroll down and see what was the result)\n",
    "\n",
    "Key achievements\n",
    "\n",
    "\n",
    "*   Explored different tokenizers available at NLTK and written custom tokenizers combining several processing steps\n",
    "*   Implemented two spellcheckers\n",
    "*   Writen n-gram language model\n",
    "*   Implemented add one, linear interpolation and backoff smoothing techniques\n",
    "*   Implemented different strategies for selecting next token: most probable, random, random weighted, random weighted with temperature\n",
    "*   Implemented beam search\n",
    "*   Experimented with different strategies for choosing first token for generation: random token, sentence deliminator token, token from user, OOV (misspelled token)\n",
    "\n"
   ],
   "metadata": {
    "id": "v0VoBa77NnwT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Load data"
   ],
   "metadata": {
    "id": "RlN61py8eaQx"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "For this lab I use my coursework: second year coursework as train text and third year coursework as test text, because for some reason coursework from current year is shorter then the one from the previous year.\n",
    "\n",
    "Let's train a language model, so it'll write diploma for me next year."
   ],
   "metadata": {
    "id": "8CwqWtCBALL4"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from pathlib import Path"
   ],
   "metadata": {
    "id": "vQy2Gi17GgDZ"
   },
   "execution_count": 2,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "with open(Path().absolute() / 'coursework_2.txt') as f:\n",
    "    train_text = f.read()\n",
    "\n",
    "with open(Path().absolute() / 'coursework_3.txt') as f:\n",
    "    test_text = f.read()"
   ],
   "metadata": {
    "id": "osQ835cIFvth"
   },
   "execution_count": 3,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Tokenizers"
   ],
   "metadata": {
    "id": "EOxCSZOWdkFO"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "QBj0bb8sqgkA",
    "outputId": "68210914-05b8-42a8-a029-40542a1d1a26"
   },
   "execution_count": 4,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "metadata": {},
     "execution_count": 4
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to tokenize sentence?"
   ],
   "metadata": {
    "id": "vx_I9sIuK0iT"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Let's examine options available with nltk library"
   ],
   "metadata": {
    "id": "xN331EAjIRP_"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk import word_tokenize, TreebankWordTokenizer, wordpunct_tokenize, TweetTokenizer, regexp_tokenize"
   ],
   "metadata": {
    "id": "7DXS7fKMv6qJ"
   },
   "execution_count": 8,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "text_sample = \"Hello-hello, (world!) How are @you?. I'm fine, but laba is killing me)\""
   ],
   "metadata": {
    "id": "gry-_NtwxDd1"
   },
   "execution_count": 9,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# standard tokenizers\n",
    "print('word_tokenize:\\n', word_tokenize(text_sample))\n",
    "print('wordpunct_tokenize:\\n', wordpunct_tokenize(text_sample))\n",
    "\n",
    "# something special\n",
    "print('TreebankWordTokenizer:\\n', TreebankWordTokenizer().tokenize(text_sample))\n",
    "print('TweetTokenizer\\n', TweetTokenizer().tokenize(text_sample))"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "IBTDNpEYv0-3",
    "outputId": "2e3ed620-c231-418a-e097-de6b7d151dd9"
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "word_tokenize:\n",
      " ['Hello-hello', ',', '(', 'world', '!', ')', 'How', 'are', '@', 'you', '?', '.', 'I', \"'m\", 'fine', ',', 'but', 'laba', 'is', 'killing', 'me', ')']\n",
      "wordpunct_tokenize:\n",
      " ['Hello', '-', 'hello', ',', '(', 'world', '!)', 'How', 'are', '@', 'you', '?.', 'I', \"'\", 'm', 'fine', ',', 'but', 'laba', 'is', 'killing', 'me', ')']\n",
      "TreebankWordTokenizer:\n",
      " ['Hello-hello', ',', '(', 'world', '!', ')', 'How', 'are', '@', 'you', '?', '.', 'I', \"'m\", 'fine', ',', 'but', 'laba', 'is', 'killing', 'me', ')']\n",
      "TweetTokenizer\n",
      " ['Hello-hello', ',', '(', 'world', '!', ')', 'How', 'are', '@you', '?', '.', \"I'm\", 'fine', ',', 'but', 'laba', 'is', 'killing', 'me', ')']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "With `regexp_tokenize` it's possible to highly customize the way tokenizer works. Not sure, whether all options listed below make sense, though. And I can come up with even more combinations, but decided it's enough)"
   ],
   "metadata": {
    "id": "8qcpC_MOImk9"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# full control\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+'))                 # select all sequences of alphanumeric chars\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+'))                 # select all sequences of alphanumeric chars\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w'))                  # select all alphanumeric chars (one by one)\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\W'))                  # select all non-alphanumeric chars (one by one), e.g. punct marks\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\S'))                  # select all non-space chars (one by one), i.e. letters + punct\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\S+'))                 # select all sequences of non-space chars (one by one), i.e. letters + punct\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+\\S\\w+'))            # select words with punctuation inside, except words consisting of one letter\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+\\S\\w+|\\w'))         # select words with punctuation inside\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+|[^\\w\\s]'))         # select words and punctuation separately\n",
    "\n",
    "print(regexp_tokenize(text_sample, pattern='\\w+\\S\\w+|[^\\w\\s]'))    # select words with punctuation inside and punctuation separately"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "3gM0SnuW1eVx",
    "outputId": "256be1e3-70e0-4fd9-8efd-5764959d83ff"
   },
   "execution_count": 11,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "['Hello', 'hello', 'world', 'How', 'are', 'you', 'I', 'm', 'fine', 'but', 'laba', 'is', 'killing', 'me']\n",
      "['Hello', 'hello', 'world', 'How', 'are', 'you', 'I', 'm', 'fine', 'but', 'laba', 'is', 'killing', 'me']\n",
      "['H', 'e', 'l', 'l', 'o', 'h', 'e', 'l', 'l', 'o', 'w', 'o', 'r', 'l', 'd', 'H', 'o', 'w', 'a', 'r', 'e', 'y', 'o', 'u', 'I', 'm', 'f', 'i', 'n', 'e', 'b', 'u', 't', 'l', 'a', 'b', 'a', 'i', 's', 'k', 'i', 'l', 'l', 'i', 'n', 'g', 'm', 'e']\n",
      "['-', ',', ' ', '(', '!', ')', ' ', ' ', ' ', '@', '?', '.', ' ', \"'\", ' ', ',', ' ', ' ', ' ', ' ', ' ', ')']\n",
      "['H', 'e', 'l', 'l', 'o', '-', 'h', 'e', 'l', 'l', 'o', ',', '(', 'w', 'o', 'r', 'l', 'd', '!', ')', 'H', 'o', 'w', 'a', 'r', 'e', '@', 'y', 'o', 'u', '?', '.', 'I', \"'\", 'm', 'f', 'i', 'n', 'e', ',', 'b', 'u', 't', 'l', 'a', 'b', 'a', 'i', 's', 'k', 'i', 'l', 'l', 'i', 'n', 'g', 'm', 'e', ')']\n",
      "['Hello-hello,', '(world!)', 'How', 'are', '@you?.', \"I'm\", 'fine,', 'but', 'laba', 'is', 'killing', 'me)']\n",
      "['Hello-hello', 'world', 'How', 'are', 'you', \"I'm\", 'fine', 'but', 'laba', 'killing']\n",
      "['Hello-hello', 'world', 'How', 'are', 'you', \"I'm\", 'fine', 'but', 'laba', 'i', 's', 'killing', 'm', 'e']\n",
      "['Hello', '-', 'hello', ',', '(', 'world', '!', ')', 'How', 'are', '@', 'you', '?', '.', 'I', \"'\", 'm', 'fine', ',', 'but', 'laba', 'is', 'killing', 'me', ')']\n",
      "['Hello-hello', ',', '(', 'world', '!', ')', 'How', 'are', '@', 'you', '?', '.', \"I'm\", 'fine', ',', 'but', 'laba', 'killing', ')']\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## How to split corpus on sentences"
   ],
   "metadata": {
    "id": "lPTEgLjVHr3q"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ],
   "metadata": {
    "id": "hvtkeW1DgvqE"
   },
   "execution_count": 12,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "sent_tokenize(text_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "owZu3X08gw8k",
    "outputId": "969ed3f6-7b65-4bb8-beb7-cd4b9d709385"
   },
   "execution_count": 13,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello-hello, (world!)',\n",
       " 'How are @you?.',\n",
       " \"I'm fine, but laba is killing me)\"]"
      ]
     },
     "metadata": {},
     "execution_count": 13
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Combine multiple functionality in CustomTokenizer"
   ],
   "metadata": {
    "id": "ZYb9WL7ZJ2f6"
   }
  },
  {
   "cell_type": "markdown",
   "source": "CustomTokenizer is based on regexp_tokenize and sent_tokenize and allows to apply several processing steps simultaneously",
   "metadata": {
    "id": "-kA0faxvJ-P9"
   }
  },
  {
   "cell_type": "markdown",
   "source": "Some options regarding weather to keep punctuation and cast to lower case:",
   "metadata": {
    "id": "kVra4OazCYuo"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from tokenizer import CustomTokenizer"
   ],
   "metadata": {
    "id": "qWTdeeSiU0ku"
   },
   "execution_count": 14,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "custom_word_tokenizer = CustomTokenizer()\n",
    "custom_word_tokenizer.tokenize_corpus(text_sample)"
   ],
   "metadata": {
    "id": "osr-KSUxiJbk",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "6993c6bb-1c54-4538-ebbb-b2742194b7d9"
   },
   "execution_count": 15,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello-hello',\n",
       " 'world',\n",
       " '<EOS>',\n",
       " 'how',\n",
       " 'are',\n",
       " 'you',\n",
       " '<EOS>',\n",
       " \"i'm\",\n",
       " 'fine',\n",
       " 'but',\n",
       " 'laba',\n",
       " 'i',\n",
       " 's',\n",
       " 'killing',\n",
       " 'm',\n",
       " 'e',\n",
       " '<EOS>']"
      ]
     },
     "metadata": {},
     "execution_count": 15
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "custom_word_tokenizer_uncased = CustomTokenizer(do_lower_case=False)\n",
    "custom_word_tokenizer_uncased.tokenize_corpus(text_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "tsK-8yAfB5xe",
    "outputId": "77ec604b-9408-4b59-a9d8-bdbd53f01ff5"
   },
   "execution_count": 16,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello-hello',\n",
       " 'world',\n",
       " '<EOS>',\n",
       " 'How',\n",
       " 'are',\n",
       " 'you',\n",
       " '<EOS>',\n",
       " \"I'm\",\n",
       " 'fine',\n",
       " 'but',\n",
       " 'laba',\n",
       " 'i',\n",
       " 's',\n",
       " 'killing',\n",
       " 'm',\n",
       " 'e',\n",
       " '<EOS>']"
      ]
     },
     "metadata": {},
     "execution_count": 16
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "custom_word_punct_tokenizer = CustomTokenizer(pattern='\\w+|[^\\w\\s]')\n",
    "custom_word_punct_tokenizer.tokenize_corpus(text_sample)"
   ],
   "metadata": {
    "id": "o0w67rla7_q3",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "f119fa79-89a4-46ae-b7d3-058f60bab387"
   },
   "execution_count": 17,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello',\n",
       " '-',\n",
       " 'hello',\n",
       " ',',\n",
       " '(',\n",
       " 'world',\n",
       " '!',\n",
       " ')',\n",
       " '<EOS>',\n",
       " 'how',\n",
       " 'are',\n",
       " '@',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " '<EOS>',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'fine',\n",
       " ',',\n",
       " 'but',\n",
       " 'laba',\n",
       " 'is',\n",
       " 'killing',\n",
       " 'me',\n",
       " ')',\n",
       " '<EOS>']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "custom_word_punct_tokenizer_uncased = CustomTokenizer(pattern='\\w+|[^\\w\\s]', do_lower_case=False)\n",
    "custom_word_punct_tokenizer_uncased.tokenize_corpus(text_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "x2jE26X880bk",
    "outputId": "2f6102aa-dca7-442a-9d1a-6d3682ff2830"
   },
   "execution_count": 18,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['Hello',\n",
       " '-',\n",
       " 'hello',\n",
       " ',',\n",
       " '(',\n",
       " 'world',\n",
       " '!',\n",
       " ')',\n",
       " '<EOS>',\n",
       " 'How',\n",
       " 'are',\n",
       " '@',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " '<EOS>',\n",
       " 'I',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'fine',\n",
       " ',',\n",
       " 'but',\n",
       " 'laba',\n",
       " 'is',\n",
       " 'killing',\n",
       " 'me',\n",
       " ')',\n",
       " '<EOS>']"
      ]
     },
     "metadata": {},
     "execution_count": 18
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Spellcheckers"
   ],
   "metadata": {
    "id": "XUtIbPDda2RY"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "Here let's compare two spellcheckers: one based on Levenshtein distance and the other uses vector representations for OOV word from fastText"
   ],
   "metadata": {
    "id": "n-m0zpbmL06u"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from spellchecking import EditDistanceSpellchecker, FastTextSpellChecker"
   ],
   "metadata": {
    "id": "tfsdmc30U7yl"
   },
   "execution_count": 19,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_tokenizer.tokenize_corpus(train_text)"
   ],
   "metadata": {
    "id": "2FiuO5o5VCs3"
   },
   "execution_count": 20,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Edit distance spellchecker"
   ],
   "metadata": {
    "id": "L59BISnlpLuB"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "edit_distance_spellchecker = EditDistanceSpellchecker()\n",
    "edit_distance_spellchecker.set_vocabulary(tokenized_train)"
   ],
   "metadata": {
    "id": "POSoCm5nlWu6"
   },
   "execution_count": 21,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "edit_distance_spellchecker.find_closest('програма')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "jeY4w5eLpsXy",
    "outputId": "bda54664-1b51-43c2-efdd-5e9f15bb5262"
   },
   "execution_count": 22,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'программа'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 22
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "edit_distance_spellchecker.find_closest('иследовательский')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "_H6Igl7npm2w",
    "outputId": "e1faffdf-2947-437b-8ceb-cd618d00d19e"
   },
   "execution_count": 23,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'исследовательский'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 23
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "edit_distance_spellchecker.find_closest('ленгвистика')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "VfLviw3rmS2v",
    "outputId": "e7de3d5b-662e-4e54-89d6-e19a1ad4ba0e"
   },
   "execution_count": 24,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'лингвистика'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 24
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "edit_distance_spellchecker.find_closest('езык')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "5aeKj4FxpGmK",
    "outputId": "5014eed4-ea2a-49d6-caef-23fc9b182314"
   },
   "execution_count": 25,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'язык'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 25
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Fasttext spellchecker"
   ],
   "metadata": {
    "id": "OxD84dREpdFE"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# download model\n",
    "!wget https://dl.fbaipublicfiles.com/fasttext/vectors-crawl/cc.ru.300.bin.gz\n",
    "!gzip -d cc.ru.300.bin.gz"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "KSIy1_RAjorr",
    "outputId": "4c707537-c242-4e74-f4cc-d6da5aa70943"
   },
   "execution_count": 2,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting fasttext\n",
      "  Downloading fasttext-0.9.2.tar.gz (68 kB)\n",
      "\u001B[2K     \u001B[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001B[0m \u001B[32m68.8/68.8 kB\u001B[0m \u001B[31m1.2 MB/s\u001B[0m eta \u001B[36m0:00:00\u001B[0m\n",
      "\u001B[?25h  Preparing metadata (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "Collecting pybind11>=2.2 (from fasttext)\n",
      "  Using cached pybind11-2.12.0-py3-none-any.whl (234 kB)\n",
      "Requirement already satisfied: setuptools>=0.7.0 in /usr/local/lib/python3.10/dist-packages (from fasttext) (67.7.2)\n",
      "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fasttext) (1.25.2)\n",
      "Building wheels for collected packages: fasttext\n",
      "  Building wheel for fasttext (setup.py) ... \u001B[?25l\u001B[?25hdone\n",
      "  Created wheel for fasttext: filename=fasttext-0.9.2-cp310-cp310-linux_x86_64.whl size=4227142 sha256=76fe683338269725bd24a2227178799da68cc873981f128379d1014deec8eb44\n",
      "  Stored in directory: /root/.cache/pip/wheels/a5/13/75/f811c84a8ab36eedbaef977a6a58a98990e8e0f1967f98f394\n",
      "Successfully built fasttext\n",
      "Installing collected packages: pybind11, fasttext\n",
      "Successfully installed fasttext-0.9.2 pybind11-2.12.0\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext_spell_check = FastTextSpellChecker()\n",
    "fasttext_spell_check.set_vocabulary(tokenized_train)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "bkwt6poHUJF-",
    "outputId": "4b39a961-bcae-42c1-b976-f835651910d3"
   },
   "execution_count": 28,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stderr",
     "text": [
      "Warning : `load_model` does not return WordVectorModel or SupervisedModel any more, but a `FastText` object which is very similar.\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext_spell_check.find_closest('иследовательский')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "nQh17qOxL3DV",
    "outputId": "8766a529-05fd-4af5-8b0e-fe48bee692a4"
   },
   "execution_count": 29,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'исследовательский'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 29
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext_spell_check.find_closest('програма')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "INYWYDi6k4W3",
    "outputId": "d1c5084c-1cef-4e30-ddcc-b19182856793"
   },
   "execution_count": 30,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'программа'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 30
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext_spell_check.find_closest('ленгвистика')"
   ],
   "metadata": {
    "id": "ii7N3QfylBv8"
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "fasttext_spell_check.find_closest('езык')"
   ],
   "metadata": {
    "id": "DyWFe1bwMO3R"
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": "Actually, fasttext-based spellchecker works much worse. FastText can handle OOV tokens, but seems like one misspelled letter greatly affects final word embedding from FastText",
   "metadata": {
    "id": "X5ztbUkQVoBj"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Language model"
   ],
   "metadata": {
    "id": "zAsfjFQOiU84"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "from language_model import LanguageModel"
   ],
   "metadata": {
    "id": "UO58mZKAVVUZ"
   },
   "execution_count": 26,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test model on toy data"
   ],
   "metadata": {
    "id": "fTwldtc2TqGc"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "three_model = LanguageModel(3)\n",
    "\n",
    "tokenized_text_sample = custom_word_punct_tokenizer.tokenize_corpus(text_sample)\n",
    "tokenized_text_sample"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ww7_T1NwK8ZP",
    "outputId": "5a95a083-e5c8-4f3c-8b6a-df93a4ad5b73"
   },
   "execution_count": 56,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['hello',\n",
       " '-',\n",
       " 'hello',\n",
       " ',',\n",
       " '(',\n",
       " 'world',\n",
       " '!',\n",
       " ')',\n",
       " '<EOS>',\n",
       " 'how',\n",
       " 'are',\n",
       " '@',\n",
       " 'you',\n",
       " '?',\n",
       " '.',\n",
       " '<EOS>',\n",
       " 'i',\n",
       " \"'\",\n",
       " 'm',\n",
       " 'fine',\n",
       " ',',\n",
       " 'but',\n",
       " 'laba',\n",
       " 'is',\n",
       " 'killing',\n",
       " 'me',\n",
       " ')',\n",
       " '<EOS>']"
      ]
     },
     "metadata": {},
     "execution_count": 56
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Perplexity with different smoothing techniques"
   ],
   "metadata": {
    "id": "BqofoENMULer"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "three_model.fit(tokenized_text_sample)"
   ],
   "metadata": {
    "id": "4-ju8WoNUJz2"
   },
   "execution_count": 57,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# test on train data just for debugging purposes\n",
    "\n",
    "three_model.estimate_perplexity(tokenized_text_sample)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "gtcqQDcrL27c",
    "outputId": "e45723fb-68c7-4fe2-c2e9-5e0c8e6ae810"
   },
   "execution_count": 58,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "metadata": {},
     "execution_count": 58
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "three_model.estimate_perplexity(tokenized_text_sample, smoothing='linear_interpolation')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1NTX0JtFTHre",
    "outputId": "6195d822-8f3f-4cf7-e12f-8fea24cd78b7"
   },
   "execution_count": 59,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0859560723351365"
      ]
     },
     "metadata": {},
     "execution_count": 59
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "three_model.estimate_perplexity(tokenized_text_sample, smoothing='backoff')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mIQsuDQcTTRN",
    "outputId": "762477b2-ab0b-42a4-b89f-3c6fc28d16c8"
   },
   "execution_count": 60,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "1.0270180507087725"
      ]
     },
     "metadata": {},
     "execution_count": 60
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Test generations"
   ],
   "metadata": {
    "id": "NpC88Db6UgTx"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# default (random token from vocab)\n",
    "\n",
    "for i, token in enumerate(three_model.generate()):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5NLsyMAFML7P",
    "outputId": "5237f4c5-a301-4cea-b0d0-3c156d898a40"
   },
   "execution_count": 61,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i\n",
      "'\n",
      "m\n",
      "fine\n",
      ",\n",
      "but\n",
      "laba\n",
      "is\n",
      "killing\n",
      "me\n",
      ")\n",
      "<EOS>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# with start/end of sentence token\n",
    "\n",
    "for i, token in enumerate(three_model.generate(prompt='<EOS>')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "UvlAK1dAM0MI",
    "outputId": "da476a37-124b-4396-8402-86e342cd9989"
   },
   "execution_count": 62,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "i\n",
      "'\n",
      "m\n",
      "fine\n",
      ",\n",
      "but\n",
      "laba\n",
      "is\n",
      "killing\n",
      "me\n",
      ")\n",
      "<EOS>\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# with prompt\n",
    "\n",
    "for i, token in enumerate(three_model.generate(prompt='killing')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "BuTseG36KIFt",
    "outputId": "40a8caa7-ece4-479c-da8c-2d2bdc44d1e8"
   },
   "execution_count": 63,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "me\n",
      ")\n",
      "<EOS>\n",
      "how\n",
      "are\n",
      "@\n",
      "you\n",
      "?\n",
      ".\n",
      "<EOS>\n",
      "i\n",
      "'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# prompt with spelling mistake (the same result as cell above)\n",
    "\n",
    "for i, token in enumerate(three_model.generate(prompt='kilin')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Q-ngd7HK_f8",
    "outputId": "e878aa52-489f-403a-cda8-542610ba8152"
   },
   "execution_count": 64,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "me\n",
      ")\n",
      "<EOS>\n",
      "how\n",
      "are\n",
      "@\n",
      "you\n",
      "?\n",
      ".\n",
      "<EOS>\n",
      "i\n",
      "'\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# beam search\n",
    "\n",
    "three_model.beam_generate(prompt='<EOS>')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "FDkKniAIU5dR",
    "outputId": "0dbe9280-3c33-4e36-ce9a-31fa55fcafc9"
   },
   "execution_count": 65,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "\"<EOS> i ' m fine , ( world ! ) <EOS> how\""
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 65
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Test model on my corpus"
   ],
   "metadata": {
    "id": "VF_Tvcw6NDzg"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Estimate perplexity"
   ],
   "metadata": {
    "id": "7ibpXqwAILsm"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bi-gram model, lower_case, clean punctuation"
   ],
   "metadata": {
    "id": "_Y0KikITFYL-"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_tokenizer.tokenize_corpus(train_text)\n",
    "tokenized_test = custom_word_tokenizer.tokenize_corpus(test_text)"
   ],
   "metadata": {
    "id": "KHdlBncANG5k"
   },
   "execution_count": 142,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model = LanguageModel(2)\n",
    "bi_model.fit(tokenized_train)\n",
    "len(bi_model.vocabulary)"
   ],
   "metadata": {
    "id": "wivQbK7hQGN2",
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "349e1acb-8cf0-4569-bb6f-00bbf36d7114"
   },
   "execution_count": 143,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3816"
      ]
     },
     "metadata": {},
     "execution_count": 143
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "u7rRaE8yPU2h",
    "outputId": "f7418dfd-0b23-4796-de17-f8c34138c7f9"
   },
   "execution_count": 144,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 144
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test, smoothing ='add_one')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "thC95IOW88m-",
    "outputId": "38ad0772-a591-4462-99b7-700e5a910830"
   },
   "execution_count": 145,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2700.9760747540154"
      ]
     },
     "metadata": {},
     "execution_count": 145
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test, smoothing ='backoff')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kYMC0KfePbE5",
    "outputId": "669ba675-d866-46c8-9396-ad241b376fe8"
   },
   "execution_count": 146,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 146
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test[:500], smoothing ='linear_interpolation')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "20l07ozqZXeI",
    "outputId": "9d216908-d515-4c6b-a4bf-af34fc9224f2"
   },
   "execution_count": 147,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "inf"
      ]
     },
     "metadata": {},
     "execution_count": 147
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Both linear_interpolation and backoff smoothing requre that at least all unigrams from test text were present in train corpus, but it's not always the case.\n",
    "\n",
    "Overall, result is not so good, but perplexity is at least less than total number of unique tokens in vocabulary, thus it's better than random guess"
   ],
   "metadata": {
    "id": "rkGXv87tyYNb"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bi-gram, keep upper case, clean punctuation"
   ],
   "metadata": {
    "id": "nk97qWsnFt8L"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_tokenizer_uncased.tokenize_corpus(train_text)\n",
    "tokenized_test = custom_word_tokenizer_uncased.tokenize_corpus(test_text)"
   ],
   "metadata": {
    "id": "cmaptHOBP056"
   },
   "execution_count": 148,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model = LanguageModel(2)\n",
    "bi_model.fit(tokenized_train)\n",
    "len(bi_model.vocabulary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "009e15f8-ce39-41b6-eb33-4f245ae075d2",
    "id": "jnSy7RsVFs8F"
   },
   "execution_count": 149,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4022"
      ]
     },
     "metadata": {},
     "execution_count": 149
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test, smoothing ='add_one')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "4104f523-121c-4bf8-8431-c2ae4a510872",
    "id": "WdD56o4VFs8G"
   },
   "execution_count": 150,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2911.0632837917447"
      ]
     },
     "metadata": {},
     "execution_count": 150
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bi-gram, lower case, keep punctuation"
   ],
   "metadata": {
    "id": "Jk5KaSmBF6az"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_punct_tokenizer.tokenize_corpus(train_text)\n",
    "tokenized_test = custom_word_punct_tokenizer.tokenize_corpus(test_text)"
   ],
   "metadata": {
    "id": "n_11I-HaF8Hh"
   },
   "execution_count": 151,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model = LanguageModel(2)\n",
    "bi_model.fit(tokenized_train)\n",
    "len(bi_model.vocabulary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9d80492e-263f-4976-8b9e-46c91ad322fd",
    "id": "LZbTMMOhF8Ho"
   },
   "execution_count": 152,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3892"
      ]
     },
     "metadata": {},
     "execution_count": 152
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test, smoothing ='add_one')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "0ef12720-bfd6-415f-d650-ebd682b0b7f2",
    "id": "j6F8aiDzF8Ho"
   },
   "execution_count": 153,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2320.516229375627"
      ]
     },
     "metadata": {},
     "execution_count": 153
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "seems like it's the best we can do"
   ],
   "metadata": {
    "id": "QwcNM4Vh1lWF"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Bi-gram, keep upper case, keep punctuation"
   ],
   "metadata": {
    "id": "G8zO2lhKG6HG"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_punct_tokenizer_uncased.tokenize_corpus(train_text)\n",
    "tokenized_test = custom_word_punct_tokenizer_uncased.tokenize_corpus(test_text)"
   ],
   "metadata": {
    "id": "_ivgcFjCG6aK"
   },
   "execution_count": 154,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model = LanguageModel(2)\n",
    "bi_model.fit(tokenized_train)\n",
    "len(bi_model.vocabulary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "986d7b56-6b9a-4cb5-a38c-1e118711a6b2",
    "id": "B-6MBLfLG6aL"
   },
   "execution_count": 155,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "4102"
      ]
     },
     "metadata": {},
     "execution_count": 155
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.estimate_perplexity(tokenized_test, smoothing ='add_one')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "c903c961-6295-458c-9efd-09b3a745455c",
    "id": "6Q3EKCC2G6aL"
   },
   "execution_count": 156,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "2467.5332264513154"
      ]
     },
     "metadata": {},
     "execution_count": 156
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### Three-gram model, lower_case, clean punctuation"
   ],
   "metadata": {
    "id": "tEHMn05cHwwC"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "tokenized_train = custom_word_tokenizer.tokenize_corpus(train_text)\n",
    "tokenized_test = custom_word_tokenizer.tokenize_corpus(test_text)"
   ],
   "metadata": {
    "id": "8Rqu50g4HwwD"
   },
   "execution_count": 157,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "three_model = LanguageModel(3)\n",
    "three_model.fit(tokenized_train)\n",
    "len(three_model.vocabulary)"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "d7fb597a-4d5f-407e-c36f-f2a1d4a60565",
    "id": "RKfCauObHwwD"
   },
   "execution_count": 158,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3816"
      ]
     },
     "metadata": {},
     "execution_count": 158
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "three_model.estimate_perplexity(tokenized_test, smoothing ='add_one')"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "outputId": "9c8c9265-c534-4770-cef2-1aa7507ef7c2",
    "id": "pIRZJbUbHwwE"
   },
   "execution_count": 159,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "3561.7082897252994"
      ]
     },
     "metadata": {},
     "execution_count": 159
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Generate text"
   ],
   "metadata": {
    "id": "f-hcEOsJId8r"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "# random token, most probable\n",
    "for i, token in enumerate(bi_model.generate()):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hTeuZifM3LTd",
    "outputId": "58cef034-be14-4c28-9e2e-a02437bfd0ae"
   },
   "execution_count": 215,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "предложений\n",
      "с\n",
      "помощью\n",
      "модели\n",
      "машинного\n",
      "обучения\n",
      ",\n",
      "а\n",
      "также\n",
      "способы\n",
      "их\n",
      "формирования\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token\n",
    "for i, token in enumerate(bi_model.generate('<EOS>')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kSXfP25kR-RQ",
    "outputId": "b0f8d465-058a-4e87-b84d-87d8c2147b56"
   },
   "execution_count": 117,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Использование\n",
      "разговорной\n",
      "лексики\n",
      "Использование\n",
      "разговорной\n",
      "лексики\n",
      "Использование\n",
      "разговорной\n",
      "лексики\n",
      "Использование\n",
      "разговорной\n",
      "лексики\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token\n",
    "for i, token in enumerate(bi_model.generate('язык')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JMnJ-8uc_8-G",
    "outputId": "7a766a10-f9b2-485c-a4d7-ea3b6bb0b6e6"
   },
   "execution_count": 261,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "программирования\n",
      "Python\n",
      "для\n",
      "текстов\n",
      ",\n",
      "а\n",
      "также\n",
      "способы\n",
      "их\n",
      "формирования\n",
      "и\n",
      "пунктуации\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token\n",
    "for i, token in enumerate(bi_model.generate('езык')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5OiX0Hh-AEp7",
    "outputId": "85f5be6b-c8dd-47f0-c12d-48f0ee99db19"
   },
   "execution_count": 262,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "программирования\n",
      "Python\n",
      "для\n",
      "текстов\n",
      ",\n",
      "а\n",
      "также\n",
      "способы\n",
      "их\n",
      "формирования\n",
      "и\n",
      "пунктуации\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token, add randomness\n",
    "for i, token in enumerate(bi_model.generate('<EOS>', mode='random_weighted')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SyrdYU4USAZW",
    "outputId": "9b1883db-74c4-4baa-9708-4d2b9359b86c"
   },
   "execution_count": 107,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Применение\n",
      "моделей\n",
      ".\n",
      "И\n",
      "вот\n",
      "казалось\n",
      "бы\n",
      ",\n",
      "синтаксиса\n",
      "и\n",
      "не\n",
      "ну\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token, add randomness,\n",
    "# pay less attention to weights with temperature set to 0.\n",
    "\n",
    "for i, token in enumerate(bi_model.generate('<EOS>',\n",
    "                                            mode='random_weighted',\n",
    "                                            temperature=0.5)):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jBhuIXoZ_N4w",
    "outputId": "59a85232-9712-46b4-d1df-d728722d645a"
   },
   "execution_count": 258,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Полученный\n",
      "датасет\n",
      "был\n",
      "куплен\n",
      "тогда\n",
      ",\n",
      "относящейся\n",
      "к\n",
      "многоклассовой\n",
      "классификации\n",
      "текстов\n",
      "/\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# start/end of sentence token, with temperature set to 1, weights are actually ignored\n",
    "\n",
    "for i, token in enumerate(bi_model.generate('<EOS>',\n",
    "                                            mode='random_weighted',\n",
    "                                            temperature=1)):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "RX5X9tFF--bZ",
    "outputId": "2f7b7889-f48c-42fa-aab3-cf5d003d3997"
   },
   "execution_count": 247,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Тогда\n",
      "первое\n",
      "предложение\n",
      "получит\n",
      "векторное\n",
      "представление\n",
      "[\n",
      "1\n",
      "/\n",
      "Известия\n",
      "отделения\n",
      "русского\n"
     ]
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "for i, token in enumerate(bi_model.generate('<EOS>', mode='random')):\n",
    "    print(token)\n",
    "    if i > 10:\n",
    "        break"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8l5itFn_Rmjx",
    "outputId": "416986ff-2a94-4a17-a65b-799b8fddb5f2"
   },
   "execution_count": 108,
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Обучая\n",
      "классификатор\n",
      "на\n",
      "это\n",
      ",\n",
      "основанные\n",
      "на\n",
      "физике\n",
      "и\n",
      "запись\n",
      "файлов\n",
      ",\n"
     ]
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "#### beam search"
   ],
   "metadata": {
    "id": "MChopVCrJCx8"
   }
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.beam_generate('<EOS>')"
   ],
   "metadata": {
    "id": "RMchhqE5k76l",
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "outputId": "9e073ccd-1b8d-4854-e4ee-58f5288f9bc7"
   },
   "execution_count": 220,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<EOS> В . <EOS> В . <EOS> В . <EOS> В .'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 220
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.beam_generate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "c2I3JfU62qkn",
    "outputId": "b40f8aa8-15d5-4657-d496-50bdd9b4db44"
   },
   "execution_count": 222,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'возникло даже с помощью модели машинного обучения , а не , а'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 222
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.beam_generate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "TochIaqh3iBA",
    "outputId": "c0191c39-12ed-478e-ac13-90ea5e62584f"
   },
   "execution_count": 223,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'нарушение орфографических , а не , а не , а не ,'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 223
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.beam_generate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "Z5vXw8KE3maY",
    "outputId": "201bcb57-d75c-4f1f-d3b3-5c0d15baeeeb"
   },
   "execution_count": 242,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'встречаются крайне редко . <EOS> В . <EOS> В . <EOS> Использование'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 242
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "bi_model.beam_generate()"
   ],
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 36
    },
    "id": "iLV3kbe4_2TN",
    "outputId": "9810b787-65d5-418c-bef3-93dbfd91ab45"
   },
   "execution_count": 246,
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "'<EOS> User identification of short texts 2017 . <EOS> В . <EOS>'"
      ],
      "application/vnd.google.colaboratory.intrinsic+json": {
       "type": "string"
      }
     },
     "metadata": {},
     "execution_count": 246
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "Seems like beam search does not allow to generate more natural text. For some reason,  sequence `<EOS> В . <EOS> В . <EOS> В . <EOS> В .` has very high probability"
   ],
   "metadata": {
    "id": "Zq9sb9ZB4LMG"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Almost the end"
   ],
   "metadata": {
    "id": "_eriYmzY5tDA"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "I've experimented with different tokenizers. The lowest perplexity was achieved with `custom_word_punct_tokenizer`, tokenizer which splits separately punctuation and alphanumeric characters. However, it should be noted that perplexity increase with increasing vocabulary size, and as use of different tokenizers results in different vocabulary size, comparison may be not fair.\n",
    "\n",
    "From two spellcheckers, I use the one based on edit distance in my text generation pipeline. I've found, that for the task of matching misspelled word with the one present in vocabulary ruled-based methods still work the best. However, if we to use context when correcting spelling mistakes, Transformers, I believe, would be the best choice.\n",
    "\n",
    "I use only add one smoothing. In my test text there are even some unigrams not present in train corpus. Therefore, perplexity cannot be estimated without smoothing, other smoothing techniques implemented in my language model don't work for the same reason.\n",
    "\n",
    "Speaking about generation, seems likes adding randomness: starting with random token, randomly choosing next token makes generated texts more interesting and natural. Beam search don't show great results in my setting. I suppose beam search works great when model can accurately predict probabilities assigned for the next token, but that's not my case. Also, it works a bit greedy, and, therefore, decreases randomness\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "id": "D6gVnce959hq"
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "# THE END!"
   ],
   "metadata": {
    "id": "u8alYPfc5gES"
   }
  }
 ]
}
