ФЕДЕРАЛЬНОЕ ГОСУДАРСТВЕННОЕ АВТОНОМНОЕ ОБРАЗОВАТЕЛЬНОЕ УЧРЕЖДЕНИЕ ВЫСШЕГО ОБРАЗОВАНИЯ
«НАЦИОНАЛЬНЫЙ ИССЛЕДОВАТЕЛЬСКИЙ УНИВЕРСИТЕТ
«ВЫСШАЯ ШКОЛА ЭКОНОМИКИ»


Факультет гуманитарных наук
Программа подготовки бакалавров по направлению
45.03.03 «Фундаментальная и прикладная лингвистика»


Шкунов Павел Андреевич 
КУРСОВАЯ РАБОТА


Исследование автоматической оценки качества больших языковых моделей при помощи синонимии языковых средств





Руководитель: 
Чураев Егор Николаевич,
Соруководитель: 
Климова Маргарита Андреевна, к. филол. н.
Научный консультант: 
Чернов Валерий Валерьевич, к. т. н.






Нижний Новгород, 2024



Оглавление
Введение	2
1. Синонимия в контексте оценки качества ответов больших языковых моделей	7
1.1. Синонимия языковых средств	7
1.1.1. Определение и критерии синонимии	7
1.1.2. Лексическая синонимия	9
1.1.3. Грамматическая синонимия	12
1.2. Основные подходы к оцениванию языковых моделей	14
1.2.1. Внутренняя и внешняя оценка языковых моделей	14
1.2.2. Особенности внутренней оценки больших языковых моделей	17
1.2.2.1. Коэффициент неопределённости	17
1.2.2.2. Формализованные тесты (бенчмарки) для оценки качества больших языковых моделей	18
2. Оценка качества больших языковых моделей на примере бенчмарка LMentry	23
2.1. Доработка задач бенчмарка: расширение списка шаблонов вопросов и правильных ответов	23
2.2. Анализ средств синонимии, встречающихся в шаблонах вопросов, сгенерированных моделью, на примере задачи bigger_number (большее число)	30
Заключение	36
Список литературы	38
Приложение	41




Введение
Синонимия является одним из важнейших явлений в языке. Использование синонимов делает речь более разнообразной и естественной. По мнению известного лингвиста И. В. Арнольд, синонимия свойственна всем языкам и служит показателем развитости языка, поскольку «богатый разносторонне развитый словарный состав имеет сильно развитую систему функциональных стилей, а богатство стилей предполагает возможность отбора, а эта последняя известную взаимозаменяемость слов, т. е. синонимику» (Арнольд, 1959: 351) 
Носители языка не испытывают трудностей в понимании синонимов, сами активно их используют. Современные большие языковые модели выступают в качестве личных ассистентов, способных выполнять простые задачи, виртуальных собеседников, готовых поддержать несложный диалог, поэтому для улучшения качества данных моделей следует стремится требовать от них тех же языковых компетенций, которыми обладают люди.
Активное развитие нейросетевых технологий способствует высокому интересу к проблеме оценки качества больших языковых моделей. На данный момент существует множество стандартизированных тестов (бенчмарков), оценивающих качество моделей по разным параметрам. Тесты могут включать в себя задачи на понимание языка, логику, математику, знания естественных и гуманитарных наук (Srivastava et al., 2023).
Качественно составленные тесты дают возможность оценивать точность больших языковых моделей и, исходя из этих данных, а также с учетом других технических характеристик модели, например, ее размера, скорости обработки запроса, выбирать наиболее подходящий для решения конкретной бизнес-задачи вариант. Таким образом, задача улучшение имеющихся бенчмарков представляет важность как для научного сообщества, так и для индустрии, что обуславливает актуальность данной работы.
Большинство работ, посвященных проблеме, уделяют недостаточное внимание влиянию языковых особенностей запросов на оценку качества больших языковых моделей. Нам известна только работа (Miaschi et al., 2021), где авторы предприняли попытку изучить корреляцию между качеством ответов модели и такими лингвистическими факторами, как длина предложения, количество грамматических основ, наличие или отсутствие отрицания, общая сложность синтаксической структуры. Научная новизна данной работы заключается в использовании синонимии языковых средств для оценки качества больших языковых моделей 
	Целью данной работы является установление влияния синонимии на качество ответов больших языковых моделей
	Для достижения поставленной цели необходимо решить следующие задачи:
    • Найти и проанализировать представленные в научной литературе определения синонимии
    • Выявить основные критерии синонимии
    • Рассмотреть особенности проявления синонимии на грамматическом и лексическом уровне
    • Изучить основные подходы к оценке качества больших языковых моделей
    • Осуществить оценку качества модели vicuna-7b-v1-3 (Chiang et al., 2023) с помощью набора стандартизированных тестов (бенчмарка) LMentry (Efrat et al., 2022).
    • Провести доработку бенчмарка LMentry с использованием синонимии языковых средств
    • Объяснение и интерпретация полученных результатов
	Объектом исследования является автоматическая оценка качества больших языковых моделей
	Предметом исследования является использование синонимии языковых средств для автоматической оценки качества больших языковых моделей
	Материалом исследования послужили ответы модели vicuna-7b-v1-3 на задачи бенчмарка LMentry; шаблоны вопросов, сгенерированные моделью gpt-3.5-turbo.
	В качестве инструментов исследования выступили язык программирования Python для написания скрипта, агрегирующего информацию по ответам модели, веб-сервис github для размещения кода проекта и совместной разработки, текстовый редактор vscode для отладки и тестирования кода, средство управления пакетами Python anaconda для создания виртуального окружения и загрузки необходимых зависимостей.
	В работе были использованы следующие методы:
    1) Метод анализа для выявления основных критериев синонимии языковых средств, особенностей проявления синонимии на уровне лексики и грамматики 
    2) Метод сравнения для сопоставления различных подходов к оценке качества больших языковых моделей
    3) Корпусный метод для верификации возможных шаблонов вопросов, сгенерированных с помощью модели gpt-3.5-turbo
    4) Программный метод для написания программы, агрегирующей информацию об ответах модели
    5) Экспериментальный метод для выбора формулировки запроса к модели gpt-3.5-turbo, дающего наиболее полный список новых шаблонов вопросов, которые могут быть получены на основе исходного шаблона вопроса через использование синонимии языковых средств
    6) Метод измерения для подсчета доли корректных ответов, вычисления стандартного отклонения данной величины и построения доверительных интервалов
    7) Метод интерпретации для формулирования выводов 















1. Синонимия в контексте оценки качества ответов больших языковых моделей 
1.1. Синонимия языковых средств
1.1.1. Определение и критерии синонимии
Синонимия может быть определена как тип семантических отношений языковых единиц, заключающийся в полном или частичном совпадении их значений (ЛЭС). Синонимия относится к числу языковых свойств, называемых языковыми универсалиями, то есть таких свойств (фонологические, морфологические, синтаксические, семантические), которые присуще всем языкам или большинству из них. Наиболее представительной и функционально разнообразной в языке является лексическая синонимия.
Помимо лексической синонимии исследователи выделяют также фразеологическую, словообразовательную, грамматическую и синтаксическую синонимию (Киселёв, 2012: 1). 
При фразеологической синонимии в языке существуют несколько фразеологических единиц, которые имеют близкое или сходное значение. Например, целый ряд фразеологизмов в русском языке обладает семантикой, которая может быть выражена как малое количество чего-либо: «капля в море» — «всего ничего» — «кот наплакал» — «раз-два и обчёлся».  
Словообразовательная синонимия характеризуется наличием в языке морфем со сходным значением. В русском языке семантической эквивалентностью обладают приставки не и без-/бес-, обозначающие отсутствие чего-либо (например, в слове «несчастный» приставка не служит индикатором отсутствия признака «счастливый», так же, как приставка без в слове «безопасный» отражает отсутствие признака «опасность»),  суффиксы  -ун, -ёр, -ец, которые обозначают лицо по действию, характерному для него («бегун», «боксёр», «гребец»), а также суффикс -ист, обозначающий лицо, занимающееся какой-либо деятельностью («футболист»).
Грамматическая синонимия является таким типом синонимии, при котором обнаруживается смысловая эквивалентность функционально тождественных грамматических форм. Пример грамматической синонимии может служить использование именительного или партитивного падежа с вещественными и некоторых другими существительными, имеющими количественное значение и обозначающими часть целого («стакан чая» — «стакан чаю»), использование краткой или полной формы прилагательных («красивый» — «красив»), использование простого глагольного сказуемого, выраженного глаголом совершенного вида, или составного глагольного сказуемого, выраженного сочетанием фазового глагола и инфинитива («запеть» — «начать петь»).  
Под синтаксической синонимией понимают синонимию, возникающую в результате применения к исходному предложению некоторого синтаксического преобразования, дающего новое предложение со сходной семантикой. Например, это может быть изменение активного залог в пассивный («Эту книгу написал он» — «Эта книга написана им»), трансформация конструкции из однородных сказуемых, отражающей семантику одновременности действий, в конструкцию с обстоятельством, выраженным деепричастным оборотом («Он вошёл в комнату и поздоровался со всеми» — «Войдя в комнату, он поздоровался со всеми»). 
В качестве критериев синонимии С. В. Киселёва предлагает использовать следующие признаки:  
    • общность выражаемого понятия 
    • наличие фонетической общности 
    • наличие морфологической общности 
    • взаимозаменяемость 
    • семантическая тождественность или близость (Киселёв, 2012: 5). 
Разумеется, данный список не является единственно возможной классификацией признаков синонимов. Так, 3вегинцев В.А также отмечает денотативную общность как условие синонимичности слов (3вегинцев, 1962: 384). Однако данный критерий не может быть применен к глагольным лексемам из-за того, что значение глагола не обладает денотативным компонентом (Киселёв, 2012: 6). В. А. Беловом было проведено исследование синонимии в устойчивых сочетаниях в, результате которого ученый пришел к выводу, что критерий взаимозаменяемости нельзя назвать «универсальным» критерием синонимии, и одна из причин тому,  –  это наличие в языке устойчивых сочетаний, так как устойчивые сочетания в отличие от свободных сочетаний, где слово можно заменить синонимом, не допускают синонимических замен (Белов, 2018: 391).  
1.1.2. Лексическая синонимия
Лексические синонимы являются одной из наиболее хорошо изученных семантических категорий (Апресян, 1995: 216). 
В лингвистике существует довольно большое число определений для лексических синонимов. Появившийся во второй половине ХХ века интерес к исследованию лексической синонимии способствовал созданию словарей синонимов.  
Автор «Краткого словаря синонимов русского языка», В. Н. Клюева, определяет синонимы как «слова-понятия, отражающие сущность одного и того же явления объективной действительности, различающиеся дополнительными оттенками <...> Синонимы служат не столько для подмены друг друга, сколько для уточнения мысли и нашего отношения к высказываемому» (Клюева, 1961: 232). З. Е. Александрова, автор одного из наиболее полных словарей синонимов русского языка, содержащего около 9000 синонимических рядов, синонимами считает «слова, которые имеют одно и то же лексическое значение, различаясь лишь оттенками значения, экспрессивной окраской и принадлежностью к тому или иному стилистическому слою языка, и которые имеют хотя бы частично совпадающую сочетаемость, т. к. только в этом случае они способны замещать друг друга в реальных контекстах» (Александрова, 1969: 600). А. П. Евгеньева определяет синонимы как «обозначающие одно и то же понятие, тождественные или близкие по значению слова, которые определенным образом соотнесены в данное время в языке и служат детализации и различению тонких смысловых оттенков понятия или выражению эксперссивных, стилистических, жанровых и иных различий» (Евгеньева, 1966: 4–29). 
По результатам исследования по выявлению критериев синонимичности слов на основе применения принципов семной семасиологии и полевой концепции языка Ю. А. Литвинова и Е. А. Маклакова дают следующее определение лексическим синонимам: “Синонимы — это семемы двух и более лексических единиц, которые, обозначая конкретное понятие, выражают один и тот же актуальный смысл, совпадают по семантическому ядру (архисема + определенный набор ядерных сем) и нормативной сочетаемости, что и определяет их способность к взаимозаменяемости в некоторых контекстах.” (Литвинова и Маклакова, 2020: 58) 
Все приведенные определения отмечают сходство основной семантики лексических синонимов при условии различия в некоторых оттенках значения. Среди возможных различий между синонимами Ю. Д. Апресян приводит такие виды различий: грамматические, стилистические, эмоционально-экспрессивные, жанровые, социальные, профессиональные, территориальные и сочетаемостные. Грамматические различия характеризуются различием набора граммем, имеющихся у каждого из синонимов пары, например глагол «видать» употребляется только в прошедшем времени, а глагол «видеть» во всех трех временах. Стилистические различия, например пара синонимов «жена» — «супруга», обуславливают выбор того или иного синонима в зависимости от стиля речи. Эмоционально-экспрессивные («лошадь» — «кляча») задают оппозицию между нейтральной и эмоционально-экспрессивной лексикой и, соответственно, также накладывают некоторые ограничения в использование синонима, относящегося к последней. Профессиональные различия связаны с терминологий употребляемой представителями определенной профессии, например пневмония в речи врачей вместо общеупотребительного воспаление легких. Территориальные различия вызваны диалектными особенностями. Сочетаемостные — ограничениями накладываемые на сочетаемость синонимичных лексем; примером синонимов с сочетаемостными различиями могут служить слова коричневый и карий, так как карий употребляется только для обозначения цвета радужки глаз (Апресян, 1995: 217). 
Таким образом, большинство лексических синонимов являются относительными. В случае же, если состав ядерных и периферийных сем двух слов  и  может быть записан в виде:

,
то есть все семы первого слова будут полностью совпадать с семами второго, то такие два слова будут считаться абсолютными или полными синонимами (лексическими дублетами) (Панченко, 2006: 163). Примером абсолютных синонимов могут служить слова языкознание и лингвистика (Белов, 2017: 23).
Существование в языке нетерминологических абсолютных синонимов А. В. Лемов связывает, во-первых, с наличием осознаваемой носителями языка внутренней формы одного синонима в противовес другому синониму иноязычного происхождения или же исконно русского происхождения,  в котором внутренняя форма (мотивировка) затемнена, например, пара синонимов «аванс» — «предоплата», во-вторых, с артикуляционно-акустическим преимущество одного из сочленов, в целом укладывающимся в принцип экономии трудовой энергии в речевых процессах, примером могут служить слова «кугуар» и «гиппопотам» и их дублетные сочлены — «пума», «бегемот», в третьих, с различной словообразовательная активность и словообразовательная функция дублетов, выраженную, например в том, для пар «доктор» — «врач» гнездо с исходным доктор содержит пять производных, а гнездо со словом «врач» — двадцать девять (Лемов, 2015: 211 - 212). 
1.1.3. Грамматическая синонимия
Понятие о синонимии возникло в лексикологии и является в этой сфере языкознания наиболее разработанным. Однако несмотря на то, что синонимия наиболее полно представлена в лексикологии, она также представлена и в словообразовании, и в грамматике (Симонова, 2021: 149).
Впервые употребил термин «грамматические синонимы» А.М. Пешковский, определяя его как «…значения слов и словосочетаний, близкие друг другу по грамматическому смыслу». Ученый отделил синтаксическую синонимию от морфологической и отмечал, что «стилистические возможности в синтаксисе гораздо многообразнее и значительнее, чем в морфологии». Главным источником синтаксической синонимии в русском языке А.М. Пешковский считал свободный порядок слов. «Благодаря ему [свободный порядок] сочетание, состоящее, например, из 5-ти полных слов (положим, “я завтра утром пойду гулять”), допускает 120 перестановок. А так как каждая перестановка слегка изменяет значение всей фразы, то получается 120 синонимов!» Лингвисту удалось выделить более 30 разрядов синтаксический синонимов, среди которых синонимика предлогов, синонимика союзов, предложные и беспредложные сочетания, союзные и бессоюзные сочетания, глагол и причастие, глагол и деепричастие, глагольное прилагательное и причастие, прилагательное и существительное, наречие в сравнительной степени и прилагательное со словом более, сочинение и подчинение, личный  и безличный типы предложений, обобщенно-личный тип вместо личного и другие разряды синтаксических синонимов (Пешковский, 1927: 57-60). 
В дальнейшем в лингвистике сложились разные подходы к изучению синтаксической синонимии: выявляли либо семантические характеристики синонимичных единиц, либо их грамматическую специфику, либо стремились изучить как содержательные, так и формальные признаки синтаксических синонимов. Выбор основы синонимической парадигмы зависел от целей исследования, поэтому единого мнения по поводу определения понятия синтаксической синонимии не было (Чуланова, 2009: 27). 
Г. А Золотова считала, что синтаксическая синонимия основывается на идентичности типовой ситуации, выражаемой разными по структуре предложениями. Ученый отмечала, что «за синонимичные принимаются такие модели предложений, которые формируются одинаковым набором одноименных, но разнооформленных структурно-семантических компонентов.» Одноименность, в понимании Г. А Золотовой, «соединяет в себе категориально-семантическое значение подкласса части речи, манифестируемого данным компонентом, и обусловленную этим значением роль его в структуре модели, подтверждаемую синтагматическими и парадигматическими координатами.» (Zolotova, 1987: 681-682) 
Е. В. Симонова обозначает следующие критерии синтаксических синонимов: 
    • возможность взаимозамены конструкций в сходном синтаксическом окружении (по крайней мере, потенциальная) 
    • близость смыслового значения разных по строению конструкций 
    • сходность грамматического значения и выполнение в структуре предложения одних и тех же синтаксических функций 
    • общность структурного строения конструкций 
    • охват достаточно большого класса (разряда) слов, которые могли бы служить для наполнения синонимичных конструкций. 
	Проанализировав данные критерии, можно отметить, что критерии для выделения синтаксических синонимов во многом схожи с критериями для выделения синонимов на других уровнях языка, например общим является критерий взаимозаменяемости, однако различаются в аспектах, связанных с особенностями синтаксических структур.  
1.2. Основные подходы к оцениванию языковых моделей
1.2.1. Внутренняя и внешняя оценка языковых моделей
Языковые модели — это модели, основанные на вычислительных графах (нейронных сетях), которые способны понимать и генерировать человеческий язык (Devlin et al., 2019: 2). Языковые модели обладают способностью оценивать вероятность появления той или иной последовательностей слов или генерировать новый текст на основе заданных входных данных, то есть создавать информативное векторное представление предшествующего контекста и решать задачу предсказания распределения вероятностей по токенам словаря для получения следующего слова последовательности. Однако языковые модели также сталкиваются с проблемами, связанными с трудностью получения качественных эмбеддингов для редко употребляемых слов, с проблемой переобучения и с трудностями в работе со сложных языковыми правилами, неоднозначностью в языке (Chang et al., 2023: 4). Исследователи постоянно работают над совершенствованием архитектуры и методов обучения языковых моделей для улучшения качества.
Большие языковые модели — это продвинутые языковые модели с огромными числом весов (обучаемых параметров). Основным модулем, лежащим в основе всех больших языковых моделей, например, таких как GPT-3, InstructGPT и GPT-4, является модуль самовнимания, предложенный в архитектуре типа Трансформер, который служит фундаментальным строительным блоком для нейросетей для задач языкового моделирования (Chang et al., 2023: 4). Трансформеры произвели революцию в области обработки естественного языка благодаря эффективной работе с последовательностями; они обеспечивают возможность распараллеливания вычислений при обработке каждого отдельного элемента последовательности и, из-за применения механизма самовнимания, хорошо справляются с выделением зависимостей между токенами, находящимися на большой дистанции друг от друга (Vaswani et al., 2017: 6–7). 
Одной из ключевых особенностей больших языковых моделей является контекстное обучение, при котором модель обучается генерировать текст на основе заданного контекста (Brown et al., 2020: 1877–1880). Модель может быть обучена на задачу предсказания случайно замаскированных токенов или же на задачу предсказания следующего токена последовательности. Обучение с подкреплением на основе обратной связи от человека является еще одним важным аспектом для улучшения качества ответов, генерируемых большими языковыми моделями. Этот метод предполагает тонкую настройку параметров модели, которая заключается в том, что модель получает разную степень вознаграждения в зависимости от качества сгенерированных ответов, что позволяет модели учиться на своих же ошибках и улучшать свою производительность с течением времени (Ziegler, 2019: 2). 
Оценка языковых моделей является одним из важнейших этапов в их разработке. Еще со времен появления первых алгоритмов для получения эмбеддингов слов в сфере обработки естественного языка сложилось противопоставление двух основных подходов к оценке качества - внешняя оценка и внутренняя оценка. При внутренней оценке рассматриваются непосредственно свойства эмбеддингов, то есть оценивается то, насколько хорошо они отражают смысл слов, для чего, например, строятся отображения векторов слов в двумерном пространстве, решается задача поиска ближайших соседей или же значения сходства для эмбеддингов слов, полученных с помощь модели сравниваются со значениями, представленными в специальных бенчмарках, собранных людьми (Zhai et al,. 2016: 4282). Внешняя оценка, наоборот, предполагает рассмотрения качества эмбеддиннгов с точки зрения решения какой-либо конкретной практической задачи, например классификация или разрешение кореферентности (Zhai et al,. 2016: 4283). 
В настоящее время для оценки больших языковых моделей выделяют также такие подходы, как экспертная оценка, включающая в себя оценку качества содержания ответов модели, при которой оценивается по какой-либо шкале ответы модели с точки зрения натуральности, связность и релевантности, а также оценка безопасности, этичности и предвзятости модели, направленная на минимизирование возможности содержания в тексте информации, отражающей предвзятое отношение к той или иной группе лиц по признаку гендера, национальности, религии или расы. Стоит отметить, что поскольку автоматизация процесс оценки, являющаяся одной из целей данной работы, — это достаточно сложная задача, то оценщиками изначально выступали и продолжают выступать люди. Например, для доработки моделей, уже находящихся в открытом доступе или представленных как часть коммерческих продуктов, применяется оценка с помощью обратной связи от пользователей моделей, проводимая с помощью опросов среди людей, использующих ту или иную модель доступную в сети Интернет (Chang et al., 2023: 7 -18). Также довольно популярными являются подходы, пытающиеся комбинировать несколько оценок (Liang et al., 2023: 2). 
1.2.2. Особенности внутренней оценки больших языковых моделей
1.2.2.1. Коэффициент неопределённости
Коэффициент неопределённости (perplexity) используется в качестве показателя для оценки языковых моделей уже в течение нескольких десятилетий, например, с помощью него оценивались модели на основе рекуррентных нейронных сетей (RNN) их модификации, такие, как модель долгосрочной и краткосрочной памяти (LSTM), предложенная в 1995 году (Hochreiter and Schmidhuber, 1995: 15). 
Возникновение данной метрики уходит своими корнями в теорию информации и статистическое языковое моделирование. Впервые концепция неопределённости в языковом моделировании была выдвинута в работах К. Шеннона в 1940-х и 1950-х годах. Шеннон ввел понятие энтропии в теорию информации, которое измеряет среднее количество информации или неопределенность, связанную со случайной величиной (Chen, 2016: 2–9). Коэффициент неопределенности может быть записан в виде:
 , где   —  это энтропия, определяемая как
.
Таким образом, коэффициент неопределенности, выводимый из формулы энтропии и изначально предложенный для задачи распознавания речи, оказался более интерпретируемой метрикой и приобрёл популярность и для задач языкового моделирования (Jelinek et al., 1977: 63).
Коэффициент неопределённости количественно определяет, насколько хорошо языковая модель предсказывает заданную последовательность слов или корпус текста или, другими словами, измеряет степень уверенности языковой модели, когда она пытается предсказать следующее слово в последовательности. Данная метрика вычисляется с использованием распределения вероятностей, сгенерированного языковой моделью, и не требует наличие размеченных данных, что является ее главным преимуществом. Чем ниже значение коэффициент неопределённости, тем лучше работает языковая модель, так как меньшее количество ошибок указывает на то, что модель более уверенно и точно предсказывает следующее слово или последовательность слов (Brown et al., 1992: 32–35).
Для моделей, состоящих только из блока кодировщика, вместо коэффициента неопределённости можно использовать метрику правдоподобия предложения, вычисляемую путем последовательного маскирования токенов предложения. Исследование (Miaschi et al., 2021: 40) показывает наличие корреляций между правдоподобием предложений и коэффициентом неопределенности для модели BERT и GPT-2. Также авторы отмечают, что на обе метрики оказывают влияние такие лингвистические факторы, как длина предложения, количество грамматических основ, наличие или отсутствие отрицания, общая сложность синтаксической структуры (Miaschi et al., 2021: 42 - 44). 
1.2.2.2. Формализованные тесты (бенчмарки) для оценки качества больших языковых моделей
Бурное развитие генеративных языковых моделей обусловило высокий интерес к проблеме оценки качества больших языковых моделей. На данный момент существует множество бенчмарков для оценки качества больших языковых моделей. В сфере информационных технологий и вычислительной техники под бенчмарком понимают процесс запуска компьютерной программы, набора программ или выполнения других операций с целью оценки функциональности объекта, путем выполнения ряда стандартных тестов, а также сам набор данных тестов (Fleming, 1986: 218–219). Остановимся подробнее на некоторых бенчмарках для языковых моделей.
Создатели бенчмарка HELM считают, что главным приоритетом должна быть прозрачность и целостность оценки. Авторы предложили холистический подход к измерению способностей модели с оценкой сразу по нескольким метрикам и на нескольких задачах обработки естественного языка. Работа исследователей включала в себя систематизацию возможных сценариев использования больших языковых моделей и показателей (то есть желаемых результатов). 
В HELM представлен набор из 16 сценариев и 7 показателей. Каждый сценарий может быть описан с точки зрения трех критериев - задача, домен, язык. Задачи включают в себя такие типы, как: ответы на вопросы, поиск информации, обобщение, обнаружение токсичности; домены представлены новостным и книжным, язык используется английский, хотя, в отличие от всех остальных бенчмарков, используется не только стандартизованный английский, но и несколько диалектных форм данного языка. Модели оцениваются по критериям, отражающим целый ряд социальных соображений (точность, устойчивость, справедливость, предвзятость, токсичность), авторы подчеркивают сложность объективной оценки по данным критерием в связи с различиями в представлениях о нормах социально приемлемого поведения (Liang et al., 2023).
Создание бенчмарка BIG-bench было инициировано исследователями из Google. BIG-bench состоит из 204 заданий, в создании которых участвовало 450 авторов из 132 организации. Темы заданий разнообразны и включают задачи из области лингвистики, математики, биологии, физики, социальных наук, рассуждений на основе здравого смысла, разработки программного обеспечения и других областей. BIG-bench фокусируется на задачах, которые, как считается, выходят за рамки возможностей современных языковых моделей. На задачах данного бенчмарка исследователями было оценено множество моделей, с количеством параметров от единиц до нескольких сотен триллиардов, включая GPT-моделей, разработанные OpenAI, внутренние модели компании Google на основе архитектуры Трансформер с различными модификациями. Кроме того, команда экспертов выполнила все задачи, чтобы обеспечить надежную базовую оценку и сравнить результаты моделей, с результатами, достигаемыми людьми. Проанализировав результаты моделей для разных задач, исследователи пришли к выводу, что:
    • увеличение числа параметров модели улучшают результаты, хотя относительный прирост в качестве не является очень значительным и не соответствует увеличению количества параметров,
    • результаты моделей, принадлежащих по своим архитектурным особенность к одному классу, очень схожи,
    • улучшение результатов с увеличением количества параметров наиболее заметно для задач, требующих большого объема знаний, владения обширным набором фактов из разных областей, в то время как для задач на логику зависимость результатов от размеров модели менее слабая (Srivastava et al., 2023).
Авторы бенчмарк BIG-bench используют метод loglikelihood (логарифм правдоподобия), основанный на оценки уверенности модели, альтернатива этому подходу – greedy until (жадная оценка). Логарифмическое правдоподобие – это распространенная метрика, используемая для оценки языковых моделей, измеряющая, насколько хорошо языковая модель присваивает вероятности заданному набору целевых токенов. Показатель логарифмического правдоподобия рассчитывается путем суммирования логарифма вероятности, назначенной каждому целевому токену. Более высокие оценки логарифмического правдоподобия указывают на лучшую качество, поскольку это означает, что языковая модель назначает более высокие вероятности правильным токенам. Жадная оценка фокусируется на качестве сгенерированного текста. В этом подходе языковая модель генерирует текст по одному токену за раз, жадно выбирая токен с наибольшей вероятностью на каждом этапе. Процесс генерации продолжается до тех пор, пока не будет выполнен заранее определенный критерий остановки, например достижение максимальной длины или создание специального токена конца последовательности. Жадная оценка не учитывает напрямую логарифмическую вероятность сгенерированного текста. Вместо этого отдается приоритет натуральности, связности и достоверности итогового результата. 
Авторы бенчмарка LMentry используют второй подход к оценке больших языковых моделей. Исследователи утверждают, что несмотря на то, что по мере быстрого роста производительность больших языковых моделей бенчмарки также становятся больше и сложнее, можно придумать достаточное количество относительно простых задач, которые, однако, будут непосильны даже для самых современных больших языковых моделей. LMentry специально разработан для обеспечения быстрой и понятной оценки возможностей и надежности больших языковых моделей. Задачи бенчмарка – например, написать предложение, содержащее определенное слово, определить, какие слова в списке относятся к определенной категории или выбрать, какое из двух слов длиннее – тривиальны для людей. Таким образом, LMentry продолжает один из подходов к оценке больших языковых моделей, обеспечивая быстрое, автоматическое и простое в запуске тестирование моделей, напоминающее модульное тестирование в разработке программного обеспечения, не прибегая к большим наборам тестов из сложных задач (Efrat et al., 2022).
Также, в отличие от бенчмарка BIG-bench, где корректность ответа модели оценивается лишь на основе вероятности, выдаваемой моделью для токена, соответствующего правильному ответу, в бенчмарке LMentry предлагается делать оценку модели на основе совпадения текста ответа, сгенерированного моделью с одним из шаблонов ответов, заранее придуманным авторами теста. Главной проблемой такого подхода является то, что довольно трудно предугадать, каким образом может быть сформулирован ответ на тот или иной вопрос, и, соответственно, составить исчерпывающий список возможных шаблонов корректных ответов. Таким образом, существует риск, что какие-либо из корректных ответов модели будут оценены системой как неверные. Основной причиной возможности составления формально различных высказываний, передающих один и тот же смысл, является использование синонимии. Практическая часть данной работы фокусируется на доработке имеющихся задач бенчмарка с учетом возможности использования синонимических конструкций, а также на анализе синонимических средств, используемых самими большими языковыми моделями.







2. Оценка качества больших языковых моделей на примере бенчмарка LMentry
2.1. Доработка задач бенчмарка: расширение списка шаблонов вопросов и правильных ответов
Бенчмарк LMentry включает в себя 25 задач, каждая из которых представляет из себя список из трех шаблонов для построения вопросов, списка паттернов ответов, которые считаются корректными, и набора метаданных, которыми заполняются слоты в шаблонах для создания запросов для тестирования модели. Например, для задачи homophones (омофоны) список шаблоном ответов был представлен следующим образом:
    • {query} sounds like {answer},
    • {query} sounds like {answer} but not like {distractor},  
    • {query} sounds like {answer} but {distractor} does not, 
    • {query} and {answer} sound alike, 
    • {query} sounds more like {answer},
    • {query} sounds more like {answer},
    • {query} sounds most {like} {answer},
    • {query} is a homophone of {answer},
    • {query} and {answer} are homophones,
    • The homophone of {query} is {answer}
Список шаблонов вопросов включал в себя шаблоны:
    1) Which word sounds like the word {query}, {word1} or {word2}?\nA:
    2) Of the two words {word1} and {word2}, which one sounds more like {query}?\nA:
    3) Which is a homophone of the word {query}, {word1} or {word2}?\nA:
	Метаданными являлся список слов омофонов. При генерации запросов случайным образом выбиралась пара из трех слов, два из которых являются омофонами (query и answer), и одно (distractor) не является омофоном двух других. В шаблонах вопросов слот, отмеченный как {query}, заполнялся словом, выбранным в качестве query, слоты {word1} и {word2} заполнялись словами, выступавшими в роле answer и distractor, при это порядок размещения (word1 – answer, word2 – distractor или word1 – distractor, word2 – answer) варьировался. Ответ модели считается правильным с уровнем уверенности, равным 1, только в том случае, если он точно соответствовал одному из шаблонов. 
Для данного исследования были выбраны только те задачи, в которых наблюдалась вариативность ответов модели и, таким образом, имелся потенциал как для изучения средств синонимии в контексте оценки качества больших языковых моделей, так и для улучшения точности результатов тестирование через корректировку шаблонов, заложенных в систему. По этой причине в работе не рассматриваются задачи, в формулировке которых прямо указывалось, что ответ должен быть односложным и в ответах модели действительно не наблюдалось вариативности (пример: задача All Words From Category, с запросом Are all the words “w1”, “w2”, “w3”, “w4”, and “w5” types of category? Answer either “yes” or “no”). Итоговый список задач, использовавший в данном исследовании, включал в себя 6 задач: bigger_number (большее число), smaller_number (меньшее число), first_alphabetically (первый по алфавиту), homophones (омофоны), rhyming_word (рифмующиеся слова), less_letters (меньше букв).
	В ходе исследования был расширен список шаблонов ответов для тех случаев, когда правильные ответы модели не засчитывались системой, так как не соответствовали ни одному из имеющихся шаблонов. Также для всех, кроме одной из выбранных задач – задачи rhyming_word (рифмующиеся слова), где предложенный нами способ составления создания новых шаблонов вопрос не дал положительных результатов – было добавлено по три шаблона вопросов.
	Таким образом, доработка включала в себя следующие этапы:
    1) Ручной анализ ответов модели
На данном этапе были просмотрены несколько семплов из ответов модели. Так как для каждой задачи (кроме задачи homophones, где количество возможных запросов ограничивалось размером списка омофонов) создавалось 3 тысячи запросов и, соответственно, получалось 3 тысячи ответов, то ручной анализ всего материала представлялся затруднительным. Для удобства обработки полученных данных было принято решение провести их агрегацию. Данный этап позволил получить начальное представление об особенностях материала, с которым предстояло работать. 
    2) Выделение наиболее часто встречающихся шаблонов в ответах модели
Для агрегирования ответов был написан скрипт на языке программирования Python. Благодаря использованию регулярных выражений удалось свести все ответы к ограниченному списку шаблонов. Например, ответ air and heir are homophones трансформировался в {query} and {answer} are homophones. Затем для каждого из шаблонов вычислялась частота встречаемости, в соответствие с которой происходило ранжирование шаблонов для получение итогового результата.
    3) Расширение списка паттернов правильных ответов
Из всех шаблонов, выделенных на предыдущем этапе, шаблоны, которые соответствовали корректным ответам и не были представлены в списке шаблонов корректных ответов добавлялись, в систему. Так, для задачи homophones (омофоны) был добавлен шаблон ответа Both words have different sounds, but {answer} sounds more {like} {query}, а для задачи rhyming_words (рифмующиеся слова) - {query} and {answer} are a rhyme. Добавление новых паттернов позволили снизить ошибку 2 типа (ошибка, возникающую, когда корректные ответы модели не были засчитаны системой как являющиеся таковыми) в случае с задачей homophones (омофоны) на 0.1%, а для задачи rhyming_words (рифмующиеся слова) на 0.3%.
    4) Оценка качества модели с учетом обновленного списка шаблонов ответов
Оценка модели осуществлялась автоматически путем запуска программы на языке Python. В таблице 1 представлены полученные результаты. Для оценки статистической значимости результатов было рассчитано значение стандартного отклонения и построены доверительные интервалы. Все эксперименты описываются случайной бернуллиевской величиной Х, которая принимает два значения: 0 - ответ на вопрос не соответствует заданному шаблону ответа и 1- соответствует. Дисперсия данной величины считалась по формуле p(1-p), где p – вероятность, что ответ модели является корректным, вычисленный как количество вопросов, на которые был получен правильный ответ, нормализованное на общее количество вопросов. Результаты оценки качества модели vicuna-7b-v1-3 представлены в таблице 1 и диаграмме 1.
    5) Создание новых шаблонов вопросов
Для создания новых шаблонов вопросов применялось два подхода. Во-первых, новые шаблоны вопросов создавались на основе синонимических конструкций, представленных в ответах модели на уже существующие вопросы, во-вторых, для генерации новых паттернов вопрос использовалась модель gpt-3.5-turbo. Перед добавлением в систему шаблонов, полученных любым из вышеприведённых методов, происходила их верификация. В случае, если использовались средства лексической синонимии, предложенные моделью слова-синонимы проверялись по кембриджскому тезаурусу английского языка, для проверки синонимических конструкций, содержащих более одного слова, использовались данные британского национального корпуса (British National Corpus). Шаблон считался корректным, если слово-синоним было представлено в кембриджском тезаурусе английского языка, или же, если поиск словосочетания (в той или иной грамматической форме) по британскому национальному корпусу выдавал некоторые примеры употребления. Полный список шаблонов вопросов представлен в приложении 1. 
Таблица 1. Доля корректных ответов для разных задач с детализаций по трем шаблонам вопросов и стандартное отклонение данной величины.
Название задачи
Доля корректных ответов
Стандартное отклонение для доли корректных ответов

Шаблон
Шаблон

№ 1
№ 2
№ 3
№ 1
№ 2
№ 3
smaller number
0.553
0.586
0.484
0.015722
0.015576
0.015803
less letters
0.463
0.525
0.241
0.015768
0.015792
0.013525
homophones
0.400
0.362
0.595
0.017321
0.016991
0.017356
first alphabetically
0.578
0.563
0.565
0.015618
0.015685
0.015677
rhyming word
0.006
0.478
0.476
0.002442
0.015796
0.015793
bigger number
0.962
0.920
0.280
0.006046
0.008579
0.014199

Диаграмма 1. Доля правильных ответов для разных задач с детализаций по трем паттернам вопросов. По вертикальной оси – доля правильных ответов, по горизонтальной оси – названия задач. Протяженность засечки соответствует ширине доверительного интервала.

На основе представленных в таблице и на диаграмме результатов можно сделать вывод о довольно сильной зависимости формы выражения вопроса и качества ответов модели.
 Особого внимания заслуживает задача rhyming_word (рифмующиеся слова). В данной задачи первый, второй и третий шаблон были сформулированы соответственно следующим образом: 
Which word rhymes with the word {query}, {word1} or {word2}?
 Which is a rhyme of the word {query}, {word1} or {word2}?
 Of the words {word1} and {word2}, which one rhymes with {query}? Несмотря на то, что каждый из трех вопрос имеет один и тот же смысл и сходство грамматической структуры (это прямые вопросы, тип вопроса – специальный), заметна очень большая разница между качеством для первого и для остальных шаблонов, в то время как доля корректных ответов для второго и третьего шаблонов практически не различается. 
Также интересны результаты для задачи bigger_number (наибольшее число): в случае с данной задачей резкое падение качество было зафиксировано для третьего шаблона вопроса. Примечательно, что в задаче smaller_number (наибольшее число), шаблоны которой синтаксически имеют абсолютно идентичную структуру шаблонам задачи bigger number (шаблоны различаются лишь использованием антонимов bigger – smaller), таких значительных различий между результатами для третьего и остальных шаблонов не наблюдается, хотя третий шаблон оказался наиболее сложным для модели в обеих задачах.  Ниже приведены шаблоны вопросов для задач bigger_number и smaller_number соответственно:
    • bigger_number
1) Which number is bigger, {n1} or {n2}?\nA:
2) Of the numbers {n1} and {n2}, which is bigger?\nA:
3) From the numbers {n1} and {n2}, write the bigger number:\n 
    • smaller_number
1) Which number is smaller, {n1} or {n2}?\nA:
2) Of the numbers {n1} and {n2}, which is smaller?\nA:
3) From the numbers {n1} and {n2}, write the smaller number:\n
Наилучшее качество было показано моделью для первого шаблона задачи bigger_number, наихудшее – для первого шаблона задачи rhyming_word. Стандартное отклонение для доли корректных ответов во всех случаях незначительное, что свидетельствует о статистической надежности полученных оценок.
2.2. Анализ средств синонимии, встречающихся в шаблонах вопросов, сгенерированных моделью, на примере задачи bigger_number (большее число)
Одной из задач, решаемых в рамках работы, было исследование возможностей больших языковых моделей создавать различные предложения с одинаковым планом содержания, используя для этого средства синонимии. В проведенном нами эксперименте была предпринята попытка сгенерировать с помощью модели gpt-3.5-turbo наибольшее возможное количество шаблонов вопросов для задачи bigger number, для чего использовался специальный запрос (промпт), который был составлен следующим образом:
You are given a sentence "Which number is bigger, {n1} or {n2}?". Generate sentences that are different from the given sentence in terms of grammar or vocabulary, but have the same meaning. Try to come up with at least 70 sentences. Then sort them so that the sentences that sound more natural appear at the top of the list.
Число 70 в запросе было выбрано путем проведения нескольких экспериментов, которые дали следующие результаты:
    1) Модель стабильно хорошо справляется с задачей генерации до 50 новых предложений. Ответы модели отличаются законченностью, не содержат опечаток и грубых ошибок
    2) Модель показывает определенные трудности при генерации более 50 новых предложений. Появляются предложения-дубликаты (в списке предложений, используемых в данной работе, уникальными являются только 64 из 70), в нескольких экспериментах модель заканчивала генерацию предложений с извинениями (пример: Is {n1I apologize for the incomplete response.), или же начинала генерировать новый список, не закончив старый.
    3) Модель не способна генерировать более 100 новых предложений. При генерации сбивается нумерация предложений, последнее предложение в списке оказывается не законченным, наблюдаются многочисленные повторы одного и того же предложения, очевидные ошибки при генерации текста, такие, как отсутствие пробелов между словами (пример: Whichnumber carries a greater numerical weight, {n1} or {n2}?)
Также было замечено, что формулировка промпта, не предполагающая ограничений на количество, не позволяет получить более широкого списка новых предложений. Использовался запрос You are given a sentence "Which number is bigger, {n1} or {n2}?". Generate sentences that are different from the given sentence in terms of grammar or vocabulary, but have the same meaning. Try to come up with as many sentences as possible. На данный запрос в 6 из 10 экспериментов модель сгенерировала список только из 10 вопросов, в 4 остальных - из 20.
Кроме того, в запрос была добавлена инструкция Then sort them so that the sentences that sound more natural appear at the top of the list, мотивирующая модель выдавать в первую очередь наиболее натуральные предложения. Исследование корреляции между оценкой натуральности предложений, полученной с помощью большой языковой модели, которая обучалась на обширном корпусе текстов из сети Интернет, и оценкой, сделанной через анкетирование носителей языка, является перспективой данной работы.
Анализ ответов показал, что модель gpt-3.5-turbo способна использовать синонимию как на уровне лексики, так и на уровне синтаксиса. Исходное предложение Which number is bigger, {n1} or {n2}? является простым вопросительным предложением, тип вопроса – специальный (wh-question). На синтаксическом уровне можно отметить следующие изменения структуры исходного предложения, встречающиеся в ответах модели:
    1) Перефразирование вопроса с использование сложноподчиненного предложения, в котором главная часть:
        a. является двусоставным предложением, которое выражает желание, внутреннюю потребность говорящего:
I need to know if {n1} or {n2} is the larger number.
I need to know if {n1} or {n2} is the larger numerical value.
I'd like to know if {n1} or {n2} is the larger numerical quantity.
I need to establish if {n1} or {n2} is the larger of the two numbers.
I'm interested to know if {n1} or {n2} is the larger numeral.
I'm interested in knowing if {n1} or {n2} is the larger number.
I'd like to know if {n1} or {n2} is the larger numerical value.
I'd like to know if {n1} or {n2} is the larger numerical quantity.
I'm curious to know which of the two numbers, {n1} or {n2}, is greater.
I'm curious to know which number, {n1} or {n2}, is bigger.
I'm wondering if {n1} is greater than {n2}, or vice versa.
I'm wondering if {n1} is greater than {n2}, or if it's the other way around.
        b. односоставным предложением, которое выражает имплицитную просьбу говорящего:
Could you determine which number is larger between {n1} and {n2}?
Could you determine the greater number between {n1} and {n2}?
Could you determine the greater of the two numbers, {n1} or {n2}?
Could you ascertain if {n1} or {n2} is the greater number?
Would you be able to discern the greater number between {n1} and {n2}?
Would you be able to ascertain if {n1} or {n2} is the greater number?
        c. является односоставным предложение со сказуемым, выраженным глаголом в повелительном наклонении:
            i. с придаточной, вводимой союзным словом which:
Please indicate which of the two numbers, {n1} or {n2}, is greater.
Please compare {n1} and {n2} and indicate which number is bigger.
Please compare {n1} and {n2} and tell me which number is larger.
            ii. с придаточной, вводимой союзом whether:
Determine whether {n1} or {n2} is the bigger number.
Determine whether {n1} or {n2} is the greater numeral.
            iii. с сентенциальным актантом, вводимым предлогом to Compare {n1} and {n2} to find out which number is larger.
Compare {n1} and {n2} to determine which number is larger.
Compare {n1} and {n2} to determine which number is greater.
    2) Перефразирование вопроса с помощью простого побудительного предложения:
Determine the larger number between {n1} and {n2}.
Compare {n1} and {n2} and tell me which one is bigger.
Please compare {n1} and {n2} and tell me which number is bigger.
Please identify the larger number between {n1} and {n2}.
Please identify the bigger number among {n1} and {n2}.
Please indicate the bigger of the two numbers, {n1} or {n2}.
Please indicate the bigger number between {n1} and {n2}.
    3) Использование общих вопросов:
Is {n1} greater than {n2}?
Is the magnitude of {n1} greater than that of {n2}?
    4) Использование альтернативных вопросов:
Is {n1} or {n2} the larger number?
Is the magnitude of {n1} greater than that of {n2}?
Is {n1} greater than {n2}, or is it the other way around?
Is {n1} or {n2} the larger numeral in this scenario?
Is {n1} or {n2} the larger numeral in this context?
Is {n1} greater than {n2}, or is it the opposite?
Is {n1} or {n2} the larger numeral in terms of value?
Таким образом, основным приемом грамматической синонимии можно назвать использование косвенного вопроса вместо прямого (пункты 1 – 2), а также изменение подтипа прямого вопроса (пункты 3 – 4).
Среди средств лексической синонимии можно отметить:
    1) Перефразирование конструкции is bigger с помощью глагольных словосочетаний (prevails in terms of magnitude, possesses a greater value, possesses a large value, has a greater value, has a higher magnitude, has a higher numerical value, has a greater magnitude, stands higher in magnitude, holds a greater value)
    2) Использование синонимов для словосочетания larger number (larger numerical value, larger numerical quantity, larger numeral, larger numeral in terms of value, larger numerical value, greater numeral, bigger number)
    3) Использование синонимов для прилагательного larger (bigger, greater)

















Заключение
В работе было рассмотрено явление синонимии как на уровне лексики, так и на уровне грамматики. Проанализированы различные определения синонимии, выделены основные критерии данного феномена. Описаны представленные в научной литературе основные подходы к оценке качества больших языковых моделей, а также сделан обзор на несколько наборов стандартизированных тестов - BIG-bench, LMentry, HELM.
Были добавлены новые шаблоны корректных ответов для задач homophones (омофоны), rhyming_words (рифмующиеся слова) бенчмарка LMentry, что позволило снизить долю ошибок второго рода при оценивании качества моделей. Расширен список шаблонов вопросов для пяти задач данного бенчмарка, что должно повысить надежность оценки качества больших языковых моделей и улучшить репрезентативность самого бенчмарка, получаемой на основе данного набора стандартизированных тестов. Проведены эксперименты, тестирующие способность больших языковых моделей к генерации новых предложений, сохраняющих смысл исходного, через использования средств языковой синонимии, а также предпринята попытка описать и классифицировать синонимические конструкции, встречающиеся в ответах модели.
Явление синонимии свойственно всем естественным языкам, синонимия языковых средств затрагивает не только лексический (исследованию лексической синонимии посвящено наибольшее количество работ), но и грамматический уровень.  Большинство исследователей выделяют такие признаки синонимов, как общность выражаемого понятия, взаимозаменяемость, семантическая тождественность или близость. При этом абсолютные синонимы встречаются в языке довольно редко – для синонимов возможно различие в некоторых оттенках значения: стилистических, эмоционально-экспрессивных, жанровых, социальных, профессиональных, территориальных и других. 
Как показали исследования с моделью vicuna-7b-v1-3, большие языковые модели очень чувствительны к форме, в которой задается вопрос. Однако четких закономерностей, какие именно синтаксические конструкции, отдельные лексемы вызывают наибольшие затруднения у модели на данном этапе выявить не удалось. Все различия в доли верных ответов для первого, второго и третьего шаблона каждой задачи носят, скорее, случайный характер. Никаких языковых особенностей, которые бы регулярным образом оказывали влияние на качество модели, отмечено не было. Исследования с моделью gpt-3.5-turbo показали, что большие языковые модели способны к использованию средств синонимии как на лексическом, так и на грамматическом уровне. 
Перспективой исследования является оценка натуральности вопросов, составленных с помощью модели gpt-3.5-turbo через анкетирование носителей языка; включение в состав бенчмарка задач, связанных с подбором синонимов и антонимов (по аналогии с задачами homophones, rhyming_words), что позволило бы получить более точное представления о способностях больших языковых моделей работать с синонимией языковых средств.







Список литературы
1. Александрова З.Е. Словарь синонимов русского языка: около 9000 синонимических рядов. Словарь синонимов русского языка / З.Е. Александрова. – Сов. энциклопедия, 1971.
2. Апресян Ю.Д. Синонимические средства языка / Ю.Д. Апресян // Избранные труды.–М.: Языки рус. культуры: Восточная литература. – 1995.
3. Арнольд И.В. Лексикология современного английского языка / И.В. Арнольд. – Высшая школа, 1973.
4. Белов В.А. Взаимозаменяемость как критерий синонимии (экспериментальное и корпусное исследование) / В.А. Белов // Вестник Санкт-Петербургского университета. Язык и литература. – 2018. – Т. 15. – № 3. – С. 390-411.
5. Белов В.А. О понятии когнитивной синонимии в зарубежной лингвистике / В.А. Белов // Взаимодействие языков и культур: материалы VI Международной научной конференции (Череповец, 26–29 апреля 2017 г.)/Под ред. ГН Чиршевой.–Череповец: ЧГУ. – 2017. – С. 22-29.
6. Киселёва С.В. К вопросу о синонимии / С.В. Киселёва // НИУ ВШЭ филиал Санкт-Петербурга. Россия. – 2012.
7. Клюева В.Н. Краткий словарь синонимов русского языка / В.Н. Клюева. – Гос. учебно-педагог. изд-во, 1961.
8. Лемов А.В. Тождественны ли дублеты-синонимы? / А.В. Лемов // Историческая и социально-образовательная мысль. – 2015. – Т. 7. – № 3. – С. 211.
9. Лингвистический энциклопедический словарь [Электронный ресурс]. – URL: https://tapemark.narod.ru/les/ (дата обращения: 28.01.2024).
10. Литвинова Ю.А. Исследование лингвистической природы синонимии лексических единиц / Ю.А. Литвинова, Е.А. Маклакова // Вестник Воронежского государственного университета. Серия: Филология. Журналистика. – 2020. – № 1. – С. 57-59.
11. Панченко Л.М. Основные подходы к определению синонимических отношений в лексике / Л.М. Панченко // Вестник Волгоградского государственного университета. Серия 2: Языкознание. – 2006. – № 5. – С. 163-165.
12. Пешковский А.М. Принципы и приемы стилистического анализа и оценки художественной прозы / А.М. Пешковский // М.: Гос. акад. художеств. наук. – 1927. – С. 57-60.
13. Симонова Е.В. К понятию грамматической синонимии / Е.В. Симонова // Актуальные вопросы изучения истории, международных отношений и культур стран Востока: Материалы IV Международной научной конференции. – Новосибирский государственный университет, 2021. – С. 27-28.
14. Чуланова А.П. К вопросу о целесообразности и значении термина «Синтаксическая синонимия» / А.П. Чуланова // Вестник Томского государственного университета. – 2009. – № 320. – С. 27-30.
15. A Survey on Evaluation of Large Language Models / Y. Chang [и др.] arXiv:2307.03109 [cs]. – arXiv, 2023.
16. An estimate of an upper bound for the entropy of English / P.F. Brown [и др.] // Computational Linguistics. – 1992. – Т. 18. – № 1. – С. 31-40.
17. BERT: Pre-training of Deep Bidirectional Transformers for Language Understanding. BERT / J. Devlin [и др.] arXiv:1810.04805 [cs]. – arXiv, 2019.
18. Beyond the Imitation Game: Quantifying and extrapolating the capabilities of language models. Beyond the Imitation Game / A. Srivastava [и др.] arXiv:2206.04615 [cs, stat]. – arXiv, 2023.
19. Chen R.X.F. A Brief Introduction to Shannon’s Information Theory / R.X.F. Chen arXiv:1612.09316 [cs, math]. – arXiv, 2021.
20. Efrat A. LMentry: A Language Model Benchmark of Elementary Language Tasks. LMentry / A. Efrat, O. Honovich, O. Levy arXiv:2211.02069 [cs]. – arXiv, 2022.
21. Hochreiter S. Long Short-Term Memory / S. Hochreiter, J. Schmidhuber // Neural Computation. – 1997. – Т. 9. – № 8. – С. 1735-1780.
22. Holistic Evaluation of Language Models / P. Liang [и др.] arXiv:2211.09110 [cs]. – arXiv, 2023.
23. Language models are few-shot learners / T. Brown [и др.] // Advances in neural information processing systems. – 2020. – Т. 33. – С. 1877-1901.
24. Perplexity—a measure of the difficulty of speech recognition tasks / F. Jelinek [и др.] // The Journal of the Acoustical Society of America. – 1977. – Т. 62. – № S1. – С. S63-S63.
25. What makes my model perplexed? a linguistic investigation on neural language models perplexity / A. Miaschi [и др.] // Proceedings of Deep Learning Inside Out (DeeLIO): The 2nd Workshop on Knowledge Extraction and Integration for Deep Learning Architectures. – 2021. – What makes my model perplexed? – С. 40-47.
26. Zhai M. Intrinsic and extrinsic evaluations of word embeddings / M. Zhai, J. Tan, J. Choi // Proceedings of the AAAI Conference on Artificial Intelligence. – 2016. – Т. 30.
27. Zolotova G.A. О дистинктивных значениях синонимических конструкций / G.A. Zolotova // Revue des études slaves. – 1987. – Т. 59. – № 3. – С. 681-686.
28. Fine-Tuning Language Models from Human Preferences / D.M. Ziegler [et al.] arXiv:1909.08593 [cs, stat]. – arXiv, 2020.



Приложение
Приложение 1.
Полный список паттернов вопросов, сгенерированных с помощью модели gpt-3.5-turbo
    1) "Is {n1} or {n2} the larger number?",
    2) "Which of the two numbers, {n1} or {n2}, is greater?",
    3) "{n1} or {n2} - which number is larger?",
    4) "Which number has a greater value, {n1} or {n2}?",
    5) "Among {n1} and {n2}, which one is the bigger number?",
    6) "{n1} and {n2} - which number is the larger one?",
    7) "Compare {n1} and {n2} and tell me which one is bigger.",
    8) "I need to know if {n1} or {n2} is the larger number.",
    9) "Could you determine which number is larger between {n1} and {n2}?",
    10)  "Which is the bigger number - {n1} or {n2}?",
    11) "I'm curious to know which of the two numbers, {n1} or {n2}, is greater.",
    12) "Is {n1} greater than {n2}, or is it the other way around?",
    13) "Of {n1} and {n2}, which one has a higher numerical value?",
    14) "Please identify the larger number between {n1} and {n2}.",
    15) "Which number prevails in terms of magnitude, {n1} or {n2}?",
    16) "Could you ascertain if {n1} or {n2} is the greater number?",
    17) "Is the magnitude of {n1} greater than that of {n2}?",
    18) "Determine whether {n1} or {n2} is the bigger number.",
    19) "Which one is the bigger numeral, {n1} or {n2}?",
    20) "Compare {n1} and {n2} to find out which number is larger.",
    21) "I'm interested to know if {n1} or {n2} is the larger numeral.",
    22) "Please indicate the bigger of the two numbers, {n1} or {n2}.",
    23) "Would you be able to discern the greater number between {n1} and {n2}?",
    24) "Which numeral possesses a greater value, {n1} or {n2}?",
    25) "I'd like to know if {n1} or {n2} is the larger numerical value.",
    26) "Could you determine the greater of the two numbers, {n1} or {n2}?",
    27) "Which number stands higher in magnitude, {n1} or {n2}?",
    28) "Is {n1} or {n2} the larger numeral in this scenario?",
    29) "I'm wondering if {n1} is greater than {n2}, or vice versa.",
    30) "Of the two numbers, {n1} and {n2}, which one is the greater?",
    31) "Please compare {n1} and {n2} and tell me which number is bigger.",
    32) "I need to establish if {n1} or {n2} is the larger of the two numbers.",
    33) "Which of {n1} and {n2} has a higher numerical value?",
    34) "Determine the larger number between {n1} and {n2}.",
    35) "Between {n1} and {n2}, which number has a greater magnitude?",
    36) "Which number possesses a greater value, {n1} or {n2}?",
    37) "Among {n1} and {n2}, which one has a higher numerical magnitude?",
    38) "Compare {n1} and {n2} to determine which number is larger.",
    39) "I'm interested in knowing if {n1} or {n2} is the larger number.",
    40) "Please indicate which of the two numbers, {n1} or {n2}, is greater.",
    41) "Would you be able to ascertain if {n1} or {n2} is the greater number?",
    42) "Which numeral holds a greater value, {n1} or {n2}?",
    43) "I'd like to know if {n1} or {n2} is the larger numerical quantity.",
    44) "Could you determine the greater number between {n1} and {n2}?",
    45) "Which number has a higher magnitude, {n1} or {n2}?",
    46) "Is {n1} or {n2} the larger numeral in terms of value?",
    47) "I'm wondering if {n1} is greater than {n2}, or if it's the other way around.",
    48) Of the two numbers, {n1} and {n2}, which one has a greater value?",
    49) "Please compare {n1} and {n2} and indicate which number is bigger.",
    50) "I need to know if {n1} or {n2} is the larger numerical value.",
    51) "Which is the larger number between {n1} and {n2}?",
    52) "I'm curious to know which number, {n1} or {n2}, is bigger.",
    53) "Is {n1} greater than {n2}, or is it the opposite?",
    54) "Which one of {n1} and {n2} has a higher numerical value?",
    55) "Please identify the bigger number among {n1} and {n2}.",
    56) "Which number has a greater magnitude, {n1} or {n2}?",
    57) "Determine whether {n1} or {n2} is the greater numeral.",
    58) "Which numeral is larger, {n1} or {n2}?",
    59) "Compare {n1} and {n2} to determine which number is greater.",
    60) "Please indicate the bigger number between {n1} and {n2}.",
    61) "Would you be able to discern the greater number among {n1} and {n2}?",
    62) "Is {n1} or {n2} the larger numeral in this context?",
    63) "Of the two numbers, {n1} and {n2}, which one is greater?",
    64) "Please compare {n1} and {n2} and tell me which number is larger."
Приложение 2
Список паттернов вопросов для задач bigger_number, smaller_number, first_alphabetically, homophones, rhyming_word, less_letters (шаблоны 1-3 были предложены авторами бенчмарка, шаблоны 3-6 добавлены нами)
    • bigger_number
1) Which number is bigger, {n1} or {n2}?\nA:
2) Of the numbers {n1} and {n2}, which is bigger?\nA:
3) From the numbers {n1} and {n2}, write the bigger number:\n 
4) Which number is larger, {n1} or {n2}?\nA:
5) Of the numbers {n1} and {n2}, which is larger?\nA:
6) From the numbers {n1} and {n2}, write the larger number:\n
    • smaller_number
1) Which number is smaller, {n1} or {n2}?\nA:
2) Of the numbers {n1} and {n2}, which is smaller?\nA:
3) From the numbers {n1} and {n2}, write the smaller number:\n
4) Which number is lesser, {n1} or {n2}?\nA:
5) Of the numbers {n1} and {n2}, which is lesser?\nA:
6) From the numbers {n1} and {n2}, write the lesser number:\n
    • first_alphabetically
1) In an alphabetical order, which of the words {word1} and {word2} comes first?\nA:
2) In an alphabetical order, which word comes first, {word1} or {word2}?\nA:
3) Of the words {word1} and {word2}, which word comes first alphabetically?\nA: 
4) In an alphabetical order, which word comes before {word1} or {word2}?\nA:
5) Which word, {word1} or {word2}, comes first when arranged in alphabetical order?\nA:
6) Of the words {word1} and {word2}, which word comes first in an alphabetical order?\nA:
    • homophones
1) Which word sounds like the word {query}, {word1} or {word2}?\nA:
2) Of the two words {word1} and {word2}, which one sounds more like {query}?\nA:
3) Which is a homophone of the word {query}, {word1} or {word2}?\nA:
4) Which word sounds simular to the word {query}, {word1} or {word2}?\nA:
5) Of the two words {word1} and {word2}, which one sounds more simular to {query}?\nA:
6) Of the two words {word1} and {word2} which one is a homophone of the word {query}?\nA:
    • rhyming_word
1) Which word rhymes with the word {query}, {word1} or {word2}?\nA:
2) Which is a rhyme of the word {query}, {word1} or {word2}?\nA:
3) Of the words {word1} and {word2}, which one rhymes with {query}?\
nA:
    • less_letters
1) Which word has fewer letters, {word1} or {word2}?\nA:
2) Which word is shorter, {word1} or {word2}?\nA:
3) Of the words {word1} and {word2} which one has fewer letters?\nA:
4) Which word has less letters, {word1} or {word2}?\nA:
5) Which word has the smaller length, {word1} or {word2}?\nA:
6) Of the words {word1} and {word2} which one has the smaller number of letters?\nA:

